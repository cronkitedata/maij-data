---
title: "First steps with data"
date:   2024-01-22
draft: false
description:  First steps in working with data in R (or really anything)
--- 

## Agenda

You might do the data dance when your FOIA is returned or you find a great dataset online. But you've only overcome the first challenge. The next one is to understand what the data represents -- what *noun* each row represents, and what characteristic, or attribute, each column will show. Then you have to actually get it into R or any other program you want to use without corrupting it. 

* Understanding data before you start ([lab](#class-lab-details))
* Reviewing data import  

## Upcoming deadlines

* [Today]{.sked-dates}: Data import prelab (10 pts) 
* [Wednesday]{.sked-dates}: Hot 100 walkthrough (10 pts)
* [Mon Jan 29]{.sked-dates}: 
    * What would you do? (25 pts)
    * Filter and sort prelab (10)
* [Wed Jan 31]{.sked-dates}: 
    * Mutate prelab (10)
    * Filter, sort & mutate lab (25)

## Preparation: 

Your prepration may take a little longer this weekend -- don't leave it until the last minute. 

[(Please do these in the order listed)]{.text-small}



* [Defining data](https://cronkitedata.github.io/djtextbook/start-data.html)  We'll come back to this later in the semester after you have some practice looking at data, but it's useful to get familiar with the ideas now. Don't do the further reading or exercises unless you really want to. Instead, try to internalize the concepts. They are fundamental to your ability to work with data. 

* Data import chapter and prelab (TK). Be sure to focus on the part about data and file types -- they're important. Submit your prelab to Canvas.

* “[Take an Interviewing Approach to Find Stories in Data](http://mediashift.org/2014/07/take-an-interviewing-approach-to-find-stories-in-data/) ”, by Derek Willis, Mediashift, July 2014.

* ["Basic steps in working with data"](https://datajournalism.com/read/handbook/one/understanding-data/basic-steps-in-working-with-data), the Data Journalism Handbook, Steve Doig, ASU Prof.

*Come to class prepared to discuss a passage from one of the following pieces that caught your eye. Remember to analyze them as a reporter, not a casual media consumer. Think about why I might have chosen these three pieces.*

Most of these relate to the pandemic and may feel dated. Try to digest them as examples of what data means, not the specifics of the stories. They may help you understand how to look at data dictionaries and the importance of granular data.

* Listen to Rob Gebeloff from the New York Times talk about the difference between granular CDC data on infections and the summary data that was used by most reporters throughout the pandemic in The Daily's "[Counting the Infected](https://www.nytimes.com/2020/07/08/podcasts/the-daily/coronavirus-data-united-states.html)"  The Daily, July 8, 2020. (His part is the first 20 minutes or so. Pay particular attention to the part beginning at about 8:00 where he talks about the difference between aggregate and granular data, and what it takes to get the latter.)

<div class="mx-auto my-3" style="width:220px">
<iframe style="border: solid 1px #e4edf2;" src="https://www.stitcher.com/embed/129650/75063201" width="220" height="150" frameborder="0" scrolling="no">
 </iframe>
</div>

* "['Very Harmful' lack of data blunts US response to outbreaks - gift link](https://www.nytimes.com/2022/09/20/us/politics/covid-data-outbreaks.html?unlocked_article_code=FRdsQf82dJp3EBYCyTtHOQZ6XenNqhytAqexFVw4uOQ61e_LdTBWGrs4wzoB6fWy2AW68kzGxoOI3GLeZC0vpQT5LVtLzcaKMS4InJOnfWRRoDWK1dvMTjz6cFWkPbrJG-nOHB0LnOgYBr8dfBrPinG0znqZIArExzAtdg0Ms-e5GXTNwtrXBB1PwyBM2sN5u1i7GnRvcZpJ633aDyv4GHuKLm53ow4r53aH54xma1rDyekLL8NVNJPy0PYMhKn8AsbyyWZq5HHFTOce_irmKCw9P_XBDqzlsCu9GbS5fALXkDzrmAxUHwjTEeYW6Ibb6uqqAzdiKGtS0qXN2LfcWyzO&smid=share-url)", Sharon LaFraniere, New York Times, September 2022. Pay particular attention to the diagram showing how the systems interact. The story reminds us not to assume we know what data exists.  

* "[Thousands allowed to bypass environmental rules in pandemic](https://apnews.com/article/virus-outbreak-ky-state-wire-ia-state-wire-ap-top-news-health-3bf753f9036e7d88f4746b1a36c1ddc4)", Associated Press, August 2020. This is a great example of looking beyond the news in front of you to collect documents that show a pattern. It shows what can be done in just a couple of months by collecting 50 states' worth of documents, once you know they should exist.  

* We measured pop music’s falsetto obsession, Vox, August 2019. This one reminds us that data is everywhere if we choose to look at it that way:  

::: {.ps-4 .ms-4}
{{< video https://www.youtube.com/embed/qJT2h5uGAC0 width="60%" height="400px">}}
:::

## Class lab details 

We will look at the promise and the limitations of working with the Phoenix Open Government’s version of the Police 911 calls for service.

Review the data elements available in [Phoenix by expanding the data dictionary](https://www.phoenixopendata.com/dataset/calls-for-service/resource/1d536ee6-7ffb-49c3-bffe-5cdd98a3c97e) below the preview table. 

Compare it to a more complete dataset made public by the [New Orleans Police Department](https://data.nola.gov/Public-Safety-and-Preparedness/Calls-for-Service-2022/nci8-thrr) (be sure to expand the “Columns in this Dataset” area)

In groups, try to evaluate your assigned question **without referring to anything other than the documentation** on these datasets: 

* What government agency did it originally come from, and what time period does it cover? What questions do you have about the columns' meanings that you would have to ask the agency or experts? (Group 1)
* Come up with three interesting questions that might be answered by this dataset -- questions that could lead to a news story.(Group 2)
* Come up with three interesting questions that you would like to write about but can’t be answered in the data's current form. (Group 3)
* If you were to request this dataset from the original source, what other pieces of information would you ask that the government include in the data? Try to imagine what else would be in the data and should be a public record, and ignore things that wouldn’t ever be in it such as information from a court file related to this call.^[Hint: Look at the New Orleans version to see what else might be held in 911 systems in general.](Group 4)

Remember that the real world process and the definitions of the data matter. 

For example, a 911 call doesn’t necessarily mean a crime was committed - it means that the police were dispatched to a specific location. Also, 911 dispatchers don’t ask for someone’s race, ethnicity or DOB when they call – just what is happening and where they are. They don’t even require your name. And there are crimes committed that never have  a 911 call – if a police officer sees someone selling drugs, there is no 911 call , just an arrest.


## Going further

Here are some more examples of datasets coming from unexpected places: historical site lines, investigative files, and Hamilton. 

- [This documentary and report](https://forensic-architecture.org/investigation/environmental-racism-in-death-alley-louisiana) by the independent firm Forensic Architecture in partnership with RISE St. James on environmental racism in "death alley", Louisiana, is quite long. But it's a great example of the emerging form of open source investigations that use imaging, historical site lines and similar non-traditional data in service of a larger piece, often conducted by human rights investigators rather than journalists.   (I can't get the direct link to work. If it won't work for you, choose Investigations, and look for those in the United States. At this writing there were only two. )

- ["Locked up and left to die"](https://www.texasobserver.org/locked-up-and-left-to-die/) , by Michael Barajas and Sophie Novack, Texas Observer, Nov. 1, 2021, is based largely on an  ambitious attempts to catalog the contents of more than 400 investigative files on jail deaths. 

- And a shoutout to this [incredible piece by The Wall Street Journal](http://graphics.wsj.com/hamilton/), tracing the roots of the musical and lyrical signatures in *Hamilton*  